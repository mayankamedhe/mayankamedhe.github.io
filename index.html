<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Mayanka Medhe</title>

    <meta name="author" content="Mayanka Medhe">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin:auto;"><tbody>
      <tr><td>
        <table style="width:100%;border:0px;border-spacing:0px;margin:auto;"><tbody>
          <tr>
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p class="name" style="text-align: center; font-size: 32px; font-weight: 600;">
                Mayanka Medhe
              </p>
              <p>
                I'm a Research Engineer at <a href="https://global.honda/en/tech/Honda_CI_Micro-mobility/">Honda R&D Tokyo</a> in the Human-Machine Interaction Team, where I develop embodied multimodal AI and smartphone-based interaction systems for autonomous micro-mobility robots like CiKoMa and WaPOCHI. My work spans <b>vision-language models</b>, <b>egocentric perception</b>, and <b>spatial reasoning</b> to enable natural interaction and user identification in complex real-world settings.
              </p>
              <p>
                Previously, I completed my M.S. from the <a href="https://www.i.u-tokyo.ac.jp/edu/entra/entra_e.shtml">University of Tokyo</a> advised by <a href="https://sites.google.com/ut-vision.org/ysato/">Prof. Yoichi Sato</a>, where I researched multimodal video understanding with eye gaze and natural language in collaboration with RIKEN CBS. I received my B.Tech. from <a href="https://www.iitb.ac.in/">IIT Bombay</a> advised by <a href="http://www.sc.iitb.ac.in/~leena/">Prof. Leena Vachhani</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:mayankaanilmedhe@gmail.com">Email</a> &nbsp;/&nbsp;
                <a href="data/Mayanka_Medhe_CV.pdf">CV</a> &nbsp;/&nbsp;
                <!-- <a href="https://scholar.google.com/">Scholar</a> &nbsp;/&nbsp; -->
                <a href="https://github.com/mayankamedhe">GitHub</a> &nbsp;/&nbsp;
                <a href="https://www.linkedin.com/in/mayanka-medhe-1087a416b/">LinkedIn</a>
              </p>
            </td>
            <td style="padding:2.5%;width:37%;max-width:37%;text-align:center">
              <a href="images/MayankaMedhe.jpg"><img style="width:100%;max-width:100%;border-radius:50%;object-fit:cover;" alt="profile photo" src="images/MayankaMedhe.jpg"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;margin-top:30px;"><tbody>
          <tr><td style="padding:16px;vertical-align:middle">
            <h2>Research Interests</h2>
            <p>
              Vision-Language Models, Egocentric Vision, Human-Robot Interaction, Scene Understanding, Spatial Reasoning for Embodied AI
            </p>
          </td></tr>
        </tbody></table>

        <table style="width:100%;margin-top:20px;"><tbody>
          <tr><td style="padding:16px;vertical-align:middle">
            <h2>Selected Work</h2>
            <p><b>Smartwatch-Robot Interaction System (Honda R&D)</b> — Led development of a vision-language control interface for micro-mobility robots via smartwatch voice commands; deployed in public PoC with 1000+ users.</p>
            <p><b>Spatial RAG Module</b> — Built a Spatial Retrieval-Augmented Generation pipeline to interpret vague geospatial natural language queries for micro-mobility navigation.</p>
            <p><b>Pedestrian Attribute Recognition</b> — Developed fine-grained person identification models for user-aware following and leading behavior in crowds.</p>
          </td></tr>
        </tbody></table>

        <table style="width:100%;margin-top:20px;"><tbody>
          <tr><td style="padding:16px;vertical-align:middle">
            <h2>Publications & Patents</h2>
            <ul>
              <li>Medhe, M., Hosomi, N. “User Localization in Camera Space using Combined User and Surrounding Object Information.” <i>JP Patent Filed</i>, 2025.</li>
              <li>Medhe, M., Kondapally, A. R., Yamada, K., Yanaka, H. “Improving Reasoning for Outdoor Navigation using Commonsense Knowledge Insertion.” <i>SICE 2023</i>.</li>
              <li>Upadhyay, U.*, Shah, N.*, Ravikanti, S.*, <b>Medhe, M.*</b> “Transformer-Based Reinforcement Learning for Games.” <i>arXiv</i>, 2019.</li>
            </ul>
          </td></tr>
        </tbody></table>

        <table style="width:100%;margin-top:20px;"><tbody>
          <tr><td style="padding:16px;vertical-align:middle">
            <h2>Education</h2>
            <p><b>University of Tokyo</b>, M.S. in Information Science & Technology (2020–2022)<br>Thesis: <a href="data/Mayanka_Medhe_masters_thesis.pdf" target="_blank"> Multimodal understanding of videos using eye gaze and natural language</a> (Advisor: Prof. Yoichi Sato)</p>
            <p><b>IIT Bombay</b>, B.Tech. in Computer Science and Engineering (2016–2020)<br>Thesis: Multi-agent path planning using reinforcement learning</p>
          </td></tr>
        </tbody></table>

      <!-- ==================== VOLUNTEERING ==================== -->
<table style="width:100%;margin-top:20px;"><tbody>
  <tr>
    <td style="padding:16px;vertical-align:middle">
      <h2>Volunteering</h2>

      <div style="display:flex;align-items:center;margin-bottom:20px;">
        <img src="images/saturdaykids.jpg" alt="Saturday Kids Japan"
             style="width:120px;height:120px;border-radius:10px;object-fit:cover;margin-right:16px;">
        <div>
          <p><b>Freelance Instructor — Saturday Kids Japan</b> (2021–2022)</p>
          <p>Conducted interactive coding and robotics workshops for children aged 5–14, using tools such as Scratch, Minecraft, and LEGO Robotics to encourage curiosity and creativity in learning.</p>
        </div>
      </div>

      <div style="display:flex;align-items:center;margin-bottom:20px;">
        <img src="images/isa.jpg" alt="ISA Japan"
             style="width:120px;height:120px;border-radius:10px;object-fit:cover;margin-right:16px;">
        <div>
          <p><b>Volunteer — ISA Japan (International School Assist)</b> (2021–2022)</p>
          <p>Organized empowerment and English-speaking programs at high schools across Japan, fostering teamwork, presentation skills, and cultural exchange among students.</p>
        </div>
      </div>

      <div style="display:flex;align-items:center;">
        <img src="images/farmfrance.jpg" alt="Farm volunteering France"
             style="width:120px;height:120px;border-radius:10px;object-fit:cover;margin-right:16px;">
        <div>
          <p><b>Farm Volunteer — France</b> (2024)</p>
          <p>Participated in sustainable farming activities, animal care, and permaculture maintenance while engaging in cultural exchange and eco-living practices in rural France.</p>
        </div>
      </div>

      </td>
      </tr>
    </tbody></table>

        <table style="width:100%;margin-top:20px;"><tbody>
          <tr><td style="padding:16px;vertical-align:middle;text-align:center;color:#777;font-size:0.9em">
            © 2025 Mayanka Medhe | Last updated November 2025<br>
            Adapted from <a href="https://github.com/jonbarron/website" target="_blank">Jon Barron’s academic website template</a>.
          </td></tr>
        </tbody></table>

      </td></tr>
    </tbody></table>
  </body>
</html>